<!DOCTYPE html>
<html lang="vi">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Qu√† t·∫∑ng ƒë·∫∑c bi·ªát d√†nh cho ch·ªã Th√∫y Min</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        video { transform: scaleX(-1); object-fit: cover; }
        canvas { position: absolute; top: 0; left: 0; pointer-events: none; }
    </style>
</head>
<body class="bg-gray-100 min-h-screen flex flex-col items-center justify-center p-4">

    <div class="bg-white p-6 rounded-3xl shadow-xl w-full max-w-sm text-center">
        <h1 class="text-2xl font-bold text-orange-500 mb-4">CH·ªä TH√öY MIN H√ÉY C∆Ø·ªúI ƒê·ªÇ NH·∫¨N QU√Ä NH√ÅüéÅ</h1>
        
        <div id="container" class="relative rounded-2xl overflow-hidden bg-black aspect-square mb-4 shadow-inner">
            <video id="video" class="w-full h-full" autoplay muted playsinline webkit-playsinline></video>
            <div id="loader" class="absolute inset-0 flex flex-col items-center justify-center bg-black bg-opacity-80 text-white p-4">
                <div class="animate-spin rounded-full h-10 w-10 border-t-2 border-orange-500 mb-2"></div>
                <p id="loader-text" class="text-sm">Ch·ªã Min ch·ªù x√≠u nh√©...</p>
            </div>
        </div>

        <div id="status" class="text-lg font-bold text-gray-600 mb-2 italic">Ch·ªã Min ch·ªù x√≠u nh√©...</div>
        
        <div class="w-full bg-gray-200 rounded-full h-3 mb-6">
            <div id="progress" class="bg-green-500 h-3 rounded-full transition-all duration-200" style="width: 0%"></div>
        </div>
        
        <button id="btn-retry" class="hidden px-4 py-2 bg-blue-500 text-white rounded-lg" onclick="location.reload()">Th·ª≠ l·∫°i</button>
    </div>

    <script>
        const video = document.getElementById('video');
        const loader = document.getElementById('loader');
        const status = document.getElementById('status');
        const progress = document.getElementById('progress');
        const btnRetry = document.getElementById('btn-retry');

        const VOUCHER_LINK = "https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExdWYxbWJnbzA4MG4xdzZ1aTl5ajkwZzRzcmE2a3cxamNxZWl2cXhxaCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/gNke2UrUTopOg/giphy.gif"; // Thay link c·ªßa b·∫°n

        async function init() {
            try {
                // 1. T·∫£i Model
                const MODEL_URL = 'https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights';
                await faceapi.nets.tinyFaceDetector.loadFromUri(MODEL_URL);
                await faceapi.nets.faceExpressionNet.loadFromUri(MODEL_URL);
                
                document.getElementById('loader-text').innerText = "Cho em quy·ªÅn camera n√†o...";

                // 2. M·ªü Camera
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    video: { 
                        facingMode: "user",
                        width: { ideal: 640 },
                        height: { ideal: 640 }
                    } 
                });
                
                video.srcObject = stream;
                
                // ƒê·∫£m b·∫£o video b·∫Øt ƒë·∫ßu ch·∫°y tr√™n mobile
                video.addEventListener('loadedmetadata', () => {
                    video.play();
                    loader.style.display = 'none';
                    status.innerText = "C∆∞·ªùi l√™n ch·ªã Min ∆°iiiii!";
                    startDetection();
                });

            } catch (err) {
                console.error(err);
                loader.style.display = 'none';
                btnRetry.classList.remove('hidden');
                status.innerText = "L·ªói: " + (err.name === 'NotAllowedError' ? "B·∫°n ƒë√£ t·ª´ ch·ªëi quy·ªÅn Camera" : "Kh√¥ng t√¨m th·∫•y camera ho·∫∑c web kh√¥ng c√≥ HTTPS");
            }
        }

        function startDetection() {
            setInterval(async () => {
                const result = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                    .withFaceExpressions();

                if (result) {
                    const happy = result.expressions.happy;
                    const score = Math.round(happy * 100);
                    
                    progress.style.width = score + "%";
                    
                    if (score > 80) {
                        status.innerText = "N·ª• c∆∞·ªùi tuy·ªát v·ªùi! Ch√∫c ch·ªã Min Gi√°ng Sinh vui v·∫ª üéâ";
                        <script>
                        const video = document.getElementById("video");
                        const statusText = document.getElementById("status");
                        const bar = document.getElementById("bar");

                        const VOUCHER_URL = "https://your-voucher-link.com";
                        const SMILE_THRESHOLD = 0.75; // expression happy
                        const MOUTH_OPEN_THRESHOLD = 0.22; // normalized mouth-opening relative to face height
                        const TEETH_PCT_THRESHOLD = 0.04; // percent of bright pixels inside mouth to consider "teeth"
                        const AUDIO_RMS_THRESHOLD = 0.02; // RMS threshold for audible laugh

                        let unlocked = false;
                        let detectionLoop = null;

                        // Audio objects
                        let audioContext = null;
                        let analyser = null;
                        let audioBuf = null;
                        let lastLoudAt = 0;

                        async function loadModels() {
                            try {
                                const URLs = [
                                    "https://cdn.jsdelivr.net/npm/face-api.js/dist/weights",
                                    "https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/weights",
                                    "https://unpkg.com/face-api.js@0.22.2/dist/weights"
                                ];

                                let loaded = false;
                                let lastError = null;

                                for (const URL of URLs) {
                                    try {
                                        console.log("Trying to load models from:", URL);
                                        await Promise.all([
                                            faceapi.nets.tinyFaceDetector.loadFromUri(URL),
                                            faceapi.nets.faceExpressionNet.loadFromUri(URL),
                                            faceapi.nets.faceLandmark68Net.loadFromUri(URL)
                                        ]);
                                        loaded = true;
                                        console.log("‚úÖ Models loaded from:", URL);
                                        break;
                                    } catch (err) {
                                        lastError = err;
                                        console.warn("Failed to load from", URL, err && err.message);
                                    }
                                }

                                if (!loaded) throw lastError || new Error("Failed to load models from all CDNs");
                                statusText.innerText = "‚úÖ Models loaded. B·∫≠t camera...";
                            } catch (error) {
                                statusText.innerText = "‚ùå L·ªói t·∫£i models: " + (error && error.message);
                                console.error("Model loading error:", error);
                                throw error;
                            }
                        }

                        async function startCamera() {
                            try {
                                const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' }, audio: true });
                                video.srcObject = stream;
                                // setup audio analyser
                                try {
                                    setupAudio(stream);
                                } catch (e) {
                                    console.warn('Audio setup failed', e);
                                }
                            } catch (error) {
                                statusText.innerText = "‚ùå L·ªói camera: " + error.message;
                                console.error("Camera error:", error);
                                throw error;
                            }
                        }

                        function setupAudio(stream) {
                            audioContext = new (window.AudioContext || window.webkitAudioContext)();
                            const source = audioContext.createMediaStreamSource(stream);
                            analyser = audioContext.createAnalyser();
                            analyser.fftSize = 1024;
                            source.connect(analyser);
                            audioBuf = new Uint8Array(analyser.fftSize);

                            function pollAudio() {
                                analyser.getByteTimeDomainData(audioBuf);
                                // compute RMS (normalized 0..1)
                                let sum = 0;
                                for (let i = 0; i < audioBuf.length; i++) {
                                    const v = (audioBuf[i] - 128) / 128;
                                    sum += v * v;
                                }
                                const rms = Math.sqrt(sum / audioBuf.length);
                                if (rms > AUDIO_RMS_THRESHOLD) {
                                    lastLoudAt = Date.now();
                                }
                                requestAnimationFrame(pollAudio);
                            }
                            pollAudio();
                        }

                        function getMouthBox(mouthPoints) {
                            let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
                            mouthPoints.forEach(p => {
                                if (p.x < minX) minX = p.x;
                                if (p.y < minY) minY = p.y;
                                if (p.x > maxX) maxX = p.x;
                                if (p.y > maxY) maxY = p.y;
                            });
                            return { x: minX, y: minY, width: Math.max(1, maxX - minX), height: Math.max(1, maxY - minY) };
                        }

                        function computeMouthOpenNormalized(mouthPoints, faceBoxHeight) {
                            // mouth height = maxY - minY among mouth points
                            let minY = Infinity, maxY = -Infinity;
                            mouthPoints.forEach(p => {
                                if (p.y < minY) minY = p.y;
                                if (p.y > maxY) maxY = p.y;
                            });
                            const mouthH = Math.max(1, maxY - minY);
                            return mouthH / faceBoxHeight;
                        }

                        async function detectTeethPercent(mouthBox) {
                            // create canvas sized to mouth region
                            const canvas = document.createElement('canvas');
                            const ctx = canvas.getContext('2d');
                            const w = Math.max(2, Math.round(mouthBox.width));
                            const h = Math.max(2, Math.round(mouthBox.height));
                            canvas.width = w;
                            canvas.height = h;
                            try {
                                ctx.drawImage(video, mouthBox.x, mouthBox.y, mouthBox.width, mouthBox.height, 0, 0, w, h);
                            } catch (e) {
                                return 0;
                            }
                            const data = ctx.getImageData(0, 0, w, h).data;
                            let bright = 0, total = 0;
                            for (let i = 0; i < data.length; i += 4) {
                                const r = data[i], g = data[i+1], b = data[i+2];
                                const lum = (r + g + b) / 3;
                                // ignore very dark pixels (inside mouth) and very small region noise
                                if (lum > 200) bright++;
                                total++;
                            }
                            return total > 0 ? bright / total : 0;
                        }

                        video.addEventListener("play", () => {
                            detectionLoop = setInterval(async () => {
                                if (unlocked) {
                                    clearInterval(detectionLoop);
                                    return;
                                }

                                try {
                                    const detection = await faceapi
                                        .detectSingleFace(video, new faceapi.TinyFaceDetectorOptions())
                                        .withFaceLandmarks()
                                        .withFaceExpressions();

                                    if (!detection) {
                                        statusText.innerText = "üò∂ Kh√¥ng th·∫•y khu√¥n m·∫∑t";
                                        bar.style.width = "0%";
                                        return;
                                    }

                                    const smile = detection.expressions.happy || 0;
                                    const faceBox = detection.detection.box;
                                    const landmarks = detection.landmarks;
                                    const mouthPoints = landmarks.getMouth();

                                    const mouthOpenNorm = computeMouthOpenNormalized(mouthPoints, faceBox.height);
                                    const mouthBox = getMouthBox(mouthPoints);
                                    const teethPct = await detectTeethPercent(mouthBox);
                                    const audioLoud = (Date.now() - (lastLoudAt || 0)) < 1600; // heard loud recently

                                    bar.style.width = Math.min(smile * 100, 100) + "%";

                                    // Build status
                                    const checks = [];
                                    checks.push(`C∆∞·ªùi: ${(smile*100).toFixed(0)}%`);
                                    checks.push(`M·ªü mi·ªáng: ${(mouthOpenNorm*100).toFixed(0)}%`);
                                    checks.push(`Nhe rƒÉng: ${(teethPct*100).toFixed(1)}%`);
                                    checks.push(`C∆∞·ªùi to: ${audioLoud ? 'C√≥' : 'Kh√¥ng'}`);
                                    statusText.innerText = checks.join(' ‚Äî ');

                                    const passSmile = smile >= SMILE_THRESHOLD;
                                    const passOpen = mouthOpenNorm >= MOUTH_OPEN_THRESHOLD;
                                    const passTeeth = teethPct >= TEETH_PCT_THRESHOLD;
                                    const passAudio = audioLoud;

                                    if (passSmile && passOpen && passTeeth && passAudio) {
                                        unlocked = true;
                                        clearInterval(detectionLoop);
                                        statusText.innerText = "üéâ Th√†nh c√¥ng! M·ªü voucher...";
                                        setTimeout(() => { window.location.href = VOUCHER_URL; }, 900);
                                    }
                                } catch (err) {
                                    console.error('Detection error', err);
                                }
                            }, 300);
                        });

                        async function init() {
                            statusText.innerText = "‚è≥ ƒêang kh·ªüi t·∫°o...";
                            let attempts = 0;
                            while (typeof faceapi === "undefined" && attempts < 50) {
                                await new Promise(resolve => setTimeout(resolve, 100));
                                attempts++;
                            }
                            if (typeof faceapi === "undefined") {
                                statusText.innerText = "‚ùå Face API kh√¥ng load. Ki·ªÉm tra k·∫øt n·ªëi internet";
                                console.error("Face API still not available after waiting");
                                return;
                            }
                            try {
                                await loadModels();
                                await startCamera();
                            } catch (error) {
                                statusText.innerText = "‚ùå L·ªói kh·ªüi t·∫°o: " + (error && error.message);
                                console.error("Init error:", error);
                            }
                        }

                        // Start initialization
                        init();
                        </script>
